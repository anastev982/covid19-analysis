{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e39a38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset exists: charged-city-421819.covid | location: EU\n",
      "Table exists: charged-city-421819.covid.owid\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud.exceptions import NotFound, Forbidden\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ID = \"charged-city-421819\"\n",
    "DESIRED_LOCATION = \"EU\"        # <-- choose \"EU\" or \"US\" once\n",
    "DATASET = \"covid\"\n",
    "TABLE = \"owid\"\n",
    "\n",
    "DATASET_FQN = f\"{PROJECT_ID}.{DATASET}\"\n",
    "TABLE_FQN   = f\"{DATASET_FQN}.{TABLE}\"\n",
    "\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "# 1) Ensure dataset exists; capture its actual location\n",
    "try:\n",
    "    ds = client.get_dataset(DATASET_FQN)\n",
    "    LOCATION = ds.location\n",
    "    print(f\"Dataset exists: {DATASET_FQN} | location: {LOCATION}\")\n",
    "except NotFound:\n",
    "    ds = bigquery.Dataset(DATASET_FQN)\n",
    "    ds.location = DESIRED_LOCATION\n",
    "    try:\n",
    "        ds = client.create_dataset(ds)                 # returns Dataset\n",
    "        LOCATION = ds.location\n",
    "        print(f\"Created dataset: {DATASET_FQN} | location: {LOCATION}\")\n",
    "    except Forbidden:\n",
    "        raise SystemExit(\n",
    "            \"No permission to create dataset. Skip the 'own table' path and use the public dataset (your main notebook already works).\"\n",
    "        )\n",
    "\n",
    "# 2) Ensure table exists; if not, create it with a small OWID sample\n",
    "try:\n",
    "    client.get_table(TABLE_FQN)\n",
    "    print(f\"Table exists: {TABLE_FQN}\")\n",
    "except NotFound:\n",
    "    print(\"Table not found; creating with a small sample…\")\n",
    "    url = \"https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv\"\n",
    "    usecols = [\n",
    "        \"iso_code\",\"location\",\"date\",\"population\",\n",
    "        \"total_cases\",\"new_cases\",\"total_deaths\",\"new_deaths\",\n",
    "        \"people_vaccinated\",\"people_fully_vaccinated\",\"total_boosters\"\n",
    "    ]\n",
    "    df = pd.read_csv(url, usecols=usecols, parse_dates=[\"date\"], nrows=100_000)\n",
    "    df[\"date\"] = df[\"date\"].dt.date\n",
    "    num_cols = [c for c in df.columns if c not in (\"iso_code\",\"location\",\"date\")]\n",
    "    df[num_cols] = df[num_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\", autodetect=True)\n",
    "    client.load_table_from_dataframe(df, TABLE_FQN, job_config=job_config).result()\n",
    "    print(\"Created table with rows:\", client.get_table(TABLE_FQN).num_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41978d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema ready: charged-city-421819.covid\n",
      "Datasets: ['covid']\n"
     ]
    }
   ],
   "source": [
    "ddl = f\"CREATE SCHEMA IF NOT EXISTS `{PROJECT_ID}.covid` OPTIONS(location='{LOCATION}')\"\n",
    "client.query(ddl, location=LOCATION).result()\n",
    "print(\"Schema ready:\", f\"{PROJECT_ID}.covid\")\n",
    "\n",
    "# sanity: list datasets we see in the project\n",
    "print(\"Datasets:\", [d.dataset_id for d in client.list_datasets(PROJECT_ID)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "caeed250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rows (from pandas): 429435\n",
      "BQ table rows (server): 429435\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "\n",
    "TABLE_ID = f\"{PROJECT_ID}.covid.owid\"   # points inside the schema we just created\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv\"\n",
    "usecols = [\n",
    "    \"iso_code\",\"location\",\"date\",\"population\",\n",
    "    \"total_cases\",\"new_cases\",\"total_deaths\",\"new_deaths\",\n",
    "    \"people_vaccinated\",\"people_fully_vaccinated\",\"total_boosters\"\n",
    "]\n",
    "\n",
    "first = True\n",
    "total_rows = 0\n",
    "for chunk in pd.read_csv(url, usecols=usecols, parse_dates=[\"date\"], chunksize=200_000):\n",
    "    # Normalize dtypes for BQ\n",
    "    chunk[\"date\"] = chunk[\"date\"].dt.date\n",
    "    num_cols = [c for c in chunk.columns if c not in (\"iso_code\",\"location\",\"date\")]\n",
    "    chunk[num_cols] = chunk[num_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        write_disposition=\"WRITE_TRUNCATE\" if first else \"WRITE_APPEND\",\n",
    "        autodetect=True,\n",
    "    )\n",
    "\n",
    "    # IMPORTANT: do NOT pass a different location here; dataset location controls it\n",
    "    job = client.load_table_from_dataframe(chunk, TABLE_ID, job_config=job_config)\n",
    "    job.result()\n",
    "\n",
    "    first = False\n",
    "    total_rows += len(chunk)\n",
    "\n",
    "print(\"Loaded rows (from pandas):\", total_rows)\n",
    "print(\"BQ table rows (server):\", client.get_table(TABLE_ID).num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af8c9cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset exists: charged-city-421819.covid | location: EU\n",
      "Table exists: charged-city-421819.covid.owid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>d</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>139.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>83369840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>83369840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>83369840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>83369840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>83369840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>83369840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>83369840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>905.0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>83369840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>83369840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>83369840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location           d  new_cases  total_cases  population\n",
       "0  Germany  2020-03-01      139.0        170.0    83369840\n",
       "1  Germany  2020-03-02        0.0        170.0    83369840\n",
       "2  Germany  2020-03-03        0.0        170.0    83369840\n",
       "3  Germany  2020-03-04        0.0        170.0    83369840\n",
       "4  Germany  2020-03-05        0.0        170.0    83369840\n",
       "5  Germany  2020-03-06        0.0        170.0    83369840\n",
       "6  Germany  2020-03-07        0.0        170.0    83369840\n",
       "7  Germany  2020-03-08      905.0       1075.0    83369840\n",
       "8  Germany  2020-03-09        0.0       1075.0    83369840\n",
       "9  Germany  2020-03-10        0.0       1075.0    83369840"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud.exceptions import NotFound, Forbidden\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ID = \"charged-city-421819\"\n",
    "DATASET_ID = \"covid\"\n",
    "TABLE_ID   = \"owid\"\n",
    "DATASET_REF = f\"{PROJECT_ID}.{DATASET_ID}\"\n",
    "TABLE_REF   = f\"{DATASET_REF}.{TABLE_ID}\"\n",
    "\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "# 1) Ensure dataset exists & capture its LOCATION\n",
    "try:\n",
    "    ds = client.get_dataset(DATASET_REF)\n",
    "    LOCATION = ds.location\n",
    "    print(\"Dataset exists:\", DATASET_REF, \"| location:\", LOCATION)\n",
    "except NotFound:\n",
    "    print(\"Dataset not found; creating in US…\")\n",
    "    ds = bigquery.Dataset(DATASET_REF)\n",
    "    ds.location = \"US\"\n",
    "    try:\n",
    "        client.create_dataset(ds)  # will fail if you lack permission\n",
    "        LOCATION = \"US\"\n",
    "        print(\"Created dataset:\", DATASET_REF, \"| location:\", LOCATION)\n",
    "    except Forbidden:\n",
    "        raise SystemExit(\n",
    "            \"No permission to create dataset. Skip your own table and keep using the public dataset \"\n",
    "            \"(your main notebook already works).\"\n",
    "        )\n",
    "\n",
    "# 2) Ensure table exists; if not, create it by loading a small sample\n",
    "try:\n",
    "    client.get_table(TABLE_REF)\n",
    "    print(\"Table exists:\", TABLE_REF)\n",
    "except NotFound:\n",
    "    print(\"Table not found; importing a small sample to create it…\")\n",
    "    url = \"https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv\"\n",
    "    usecols = [\n",
    "        \"iso_code\",\"location\",\"date\",\"population\",\n",
    "        \"total_cases\",\"new_cases\",\"total_deaths\",\"new_deaths\",\n",
    "        \"people_vaccinated\",\"people_fully_vaccinated\",\"total_boosters\"\n",
    "    ]\n",
    "    df = pd.read_csv(url, usecols=usecols, parse_dates=[\"date\"], nrows=100_000)\n",
    "    df[\"date\"] = df[\"date\"].dt.date\n",
    "    num_cols = [c for c in df.columns if c not in (\"iso_code\",\"location\",\"date\")]\n",
    "    df[num_cols] = df[num_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\", autodetect=True)\n",
    "    client.load_table_from_dataframe(df, TABLE_REF, job_config=job_config).result()\n",
    "    print(\"Created table with rows:\", client.get_table(TABLE_REF).num_rows)\n",
    "\n",
    "# 3) Sanity query (note: use LOCATION detected above)\n",
    "sql = f\"\"\"\n",
    "SELECT location, DATE(date) AS d, new_cases, total_cases, population\n",
    "FROM `{TABLE_REF}`\n",
    "WHERE location IN ('Serbia','Norway','Germany')\n",
    "  AND date BETWEEN DATE('2020-03-01') AND DATE('2022-12-31')\n",
    "ORDER BY location, d\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "df_check = client.query(sql, location=LOCATION).result().to_dataframe()\n",
    "df_check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a473a362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>d</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>139.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>83369840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>83369840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>83369840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>83369840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>83369840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>83369840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>83369840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>905.0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>83369840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>83369840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>83369840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location           d  new_cases  total_cases  population\n",
       "0  Germany  2020-03-01      139.0        170.0    83369840\n",
       "1  Germany  2020-03-02        0.0        170.0    83369840\n",
       "2  Germany  2020-03-03        0.0        170.0    83369840\n",
       "3  Germany  2020-03-04        0.0        170.0    83369840\n",
       "4  Germany  2020-03-05        0.0        170.0    83369840\n",
       "5  Germany  2020-03-06        0.0        170.0    83369840\n",
       "6  Germany  2020-03-07        0.0        170.0    83369840\n",
       "7  Germany  2020-03-08      905.0       1075.0    83369840\n",
       "8  Germany  2020-03-09        0.0       1075.0    83369840\n",
       "9  Germany  2020-03-10        0.0       1075.0    83369840"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = f\"\"\"\n",
    "SELECT location, DATE(date) AS d, new_cases, total_cases, population\n",
    "FROM `{TABLE_FQN}`\n",
    "WHERE location IN ('Serbia','Norway','Germany')\n",
    "  AND date BETWEEN DATE('2020-03-01') AND DATE('2022-12-31')\n",
    "ORDER BY location, d\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "df_check = client.query(sql, location=LOCATION).result().to_dataframe()\n",
    "df_check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2fb78996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets: ['covid']\n"
     ]
    }
   ],
   "source": [
    "print(\"Datasets:\", [d.dataset_id for d in client.list_datasets(PROJECT_ID)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d672c621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client(project=\"charged-city-421819\")\n",
    "\n",
    "# Try to fetch the dataset directly\n",
    "try:\n",
    "    ds = client.get_dataset(\"charged-city-421819.covid\")\n",
    "    print(\"Found dataset:\", ds.full_dataset_id, \"| location:\", ds.location)\n",
    "except Exception as e:\n",
    "    print(\"get_dataset error:\", e)\n",
    "\n",
    "# List all datasets you can see (with locations)\n",
    "info = []\n",
    "for d in client.list_datasets(\"charged-city-421819\"):\n",
    "    loc = client.get_dataset(d).location\n",
    "    info.append((d.dataset_id, loc))\n",
    "print(\"Datasets:\", info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6a9a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCATION = \"EU\"   # set to the dataset's location\n",
    "# For queries:\n",
    "df = client.query(\"SELECT 1 AS ok\", location=LOCATION).result().to_dataframe()\n",
    "# For loads: do NOT override location; the dataset's location is used automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a069d85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (WSL spectromind)",
   "language": "python",
   "name": "spectromind"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
